{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7278c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Import required modules\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_core.runnables import RunnableLambda, RunnableMap\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.load import dumps, loads\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from fastapi.responses import StreamingResponse\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68372cd1",
   "metadata": {},
   "source": [
    "Embedding Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc85403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2969326/542832890.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n",
      "/home/sfnavas-f/Projects/DomainMind/.venv/lib/python3.13/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Embed the text content in split_docs\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/e5-base-v2\",\n",
    "    model_kwargs={\"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"},\n",
    "    encode_kwargs={\"normalize_embeddings\": True},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba40d29c",
   "metadata": {},
   "source": [
    "Load Existing Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0667c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2969326/360242083.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "# Load the vector store\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=\"../data/doc_vectordb\",\n",
    "    embedding_function=embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57af8257",
   "metadata": {},
   "source": [
    "Retriever Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08eaa3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bdfd77",
   "metadata": {},
   "source": [
    "Setting up Local LLM with Ollama. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d36b65bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2969326/1280228933.py:1: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"qwen3:8b\", base_url=\"http://localhost:11434\", streaming=True)\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(model=\"qwen3:8b\", base_url=\"http://localhost:11434\", streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b73b06",
   "metadata": {},
   "source": [
    "MultiQuery Generation Chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35f58c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"You are an AI scientific research assistant. Your task is to generate two \n",
    "different versions of the given user question and the conversation history so far to retrieve relevant documents from a vector \n",
    "database. The vector database consists of scientific papers, articles, books and other academic \n",
    "resources related to the field of Statistical Physics, Computational Physics, Statistics, Soft-Matter Physics\n",
    "and other related fields. By generating multiple perspectives on the user question, your goal is to help\n",
    "the user overcome some of the limitations of the distance-based similarity search. \n",
    "Provide these alternative questions separated by newlines. If the below question is unrelated or does not require\n",
    "additional context, you can respond with \"No relevant questions found.\"\n",
    "Original question: {question}\n",
    "Conversation history: {history}\"\"\"\n",
    "multi_prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "\n",
    "def remove_think_blocks(text):\n",
    "    # Remove all <think>...</think> blocks from the text\n",
    "    return re.sub(r\"<think>.*?</think>\", \"\", text, flags=re.DOTALL).strip()\n",
    "\n",
    "\n",
    "# Query generation cHAIN\n",
    "generate_query_chain = (\n",
    "    multi_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | remove_think_blocks\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db59746",
   "metadata": {},
   "source": [
    "Retrieval Chain for multiple queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f36e02ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make a single list of the retrieved documents\n",
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\"Unique union of retrieved docs\"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flattened_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique documents\n",
    "    unique_docs = list(set(flattened_docs))\n",
    "    # Return\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "\n",
    "# Retrieval Chain\n",
    "retrieval_chain = generate_query_chain | retriever.map() | get_unique_union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421c7e8",
   "metadata": {},
   "source": [
    "# Summary Chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d4ac8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "template = \"\"\"\n",
    "You are an AI scientific research assistant. Summarize the following conversation between a user and an assistant.\n",
    "- Focus on the key points, main ideas, and any important questions and answers.\n",
    "- Exclude irrelevant, repetitive, or off-topic content.\n",
    "- Use your own words; do not copy the conversation verbatim.\n",
    "- Keep the summary concise and within 512-1024 tokens.\n",
    "- Format the summary as a narration of how the conversation between the user and the assistant unfolded.\n",
    "\n",
    "Original conversation:\n",
    "{history}\n",
    "\"\"\"\n",
    "summarization_prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Summarization chain\n",
    "summarization_chain = (\n",
    "    summarization_prompt | llm | StrOutputParser() | remove_think_blocks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a982fe82",
   "metadata": {},
   "source": [
    "Testing the working of the summarization chain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdfb3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example conversation history\n",
    "history = [\n",
    "    HumanMessage(content=\"What is self-aggregation?\"),\n",
    "    AIMessage(\n",
    "        content=\"Self-aggregation is the process by which molecules or particles spontaneously organize into ordered structures.\"\n",
    "    ),\n",
    "    HumanMessage(content=\"Why is it important in materials science?\"),\n",
    "    AIMessage(\n",
    "        content=\"It's important because it can lead to new material properties and functionalities.\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8a609fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: The conversation begins with the user asking for a definition of \"self-aggregation,\" to which the assistant responds by explaining it as a process where molecules or particles spontaneously form ordered structures. The user then inquires about its importance in materials science, and the assistant highlights its significance in enabling novel material properties and functionalities. The exchange focuses on clarifying the concept and its relevance, with the assistant providing concise, direct answers to the user’s questions. No extraneous details are included, and the summary captures the core ideas and progression of the dialogue.\n"
     ]
    }
   ],
   "source": [
    "# See what summary is produced\n",
    "summary = summarization_chain.invoke({\"history\": history})\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f90470b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be used to print the prompt  within the RAG chain\n",
    "def debug_prompt(messages):\n",
    "    print(\"Prompt to LLM:\")\n",
    "    for m in messages:\n",
    "        print(f\"{type(m).__name__}: {getattr(m, 'content', m)}\")\n",
    "    return messages\n",
    "\n",
    "\n",
    "# | RunnableLambda(debug_prompt) Insert this right after the prompt prep and right before the llm call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b24dd4",
   "metadata": {},
   "source": [
    "# RAG Chain \n",
    "\n",
    "Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cf06ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"\"\"\n",
    "        You are a helpful scientific assistant.  \n",
    "        You need to answer the question in a scientifically sound manner, combining your own knowledge and the \n",
    "        provided context and the conversation history. If you use information from the provided context, cite it. \n",
    "        If the answer is based on your own knowledge, state so.\n",
    "        The conversation history is provided above. You also have further context regarding the current question \n",
    "        below from snippets from various scientific papers. \n",
    "        \"\"\"\n",
    "    ),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"Context:\\n{context}\\n\\nQuestion: {question}\\n\\n History: {history}\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "\n",
    "rag_chain_multi_query = (\n",
    "    {\n",
    "        \"history\": RunnableLambda(\n",
    "            lambda x: summarization_chain.invoke({\"history\": x[\"history\"]})\n",
    "        ),\n",
    "        \"context\": RunnableLambda(\n",
    "            lambda x: retrieval_chain.invoke(\n",
    "                {\n",
    "                    \"question\": x[\"question\"],\n",
    "                    \"history\": summarization_chain.invoke({\"history\": x[\"history\"]}),\n",
    "                }\n",
    "            )\n",
    "        ),\n",
    "        \"question\": RunnableLambda(lambda x: (x[\"question\"])),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e070bfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio history: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfnavas-f/Projects/DomainMind/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n",
      "/tmp/ipykernel_2969326/3087458109.py:9: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  return [loads(doc) for doc in unique_docs]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio history: [{'role': 'user', 'metadata': None, 'content': 'What are colloidal particles?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': \"<details><summary><b>🤔 Thinking</b></summary><pre>Okay, the user is asking about colloidal particles. Let me start by recalling what I know. Colloidal particles are tiny particles suspended in a fluid, right? They're bigger than molecules but smaller than what's visible to the naked eye. Wait, the user provided some documents, so I should check those for specific info.\\n\\nLooking at the documents, there's a mention of colloidal particles in different contexts. For example, one document talks about colloidal systems and hydrodynamic interactions. Another mentions colloidal self-assembly, both passive and active systems. There's also a reference to interactions like phoretic, osmotic, and hydrodynamic. \\n\\nSo, colloidal particles are particles dispersed in a medium, usually liquid, with sizes between 1 nm to 1 micrometer. They can be coated with polymers, as mentioned in one of the texts. The interactions between them include direct potential interactions and indirect hydrodynamic ones. Also, active colloids can move autonomously due to external fields or chemical gradients. \\n\\nI should structure the answer to define colloidal particles, their size range, the medium they're in, and the types of interactions they have. Also, mention their applications like self-assembly and biomedical uses. Need to make sure to reference the documents where applicable, like the hydrodynamic interactions from Dhont's work and the active systems from Huang's paper. Avoid any markdown and keep it clear.</pre></details>\\n\\nColloidal particles are tiny, dispersed entities suspended in a fluid medium (such as liquid or gas), typically ranging in size from **1 nanometer to 1 micrometer**. They are larger than individual molecules or ions but smaller than particles visible to the naked eye. These particles can consist of various materials, such as polymers, inorganic compounds, or biological entities, and are often stabilized by surface coatings or repulsive forces to prevent aggregation.  \\n\\nKey characteristics and contexts from the provided documents:  \\n1. **Hydrodynamic Interactions**: Colloidal particles induce fluid flow around them, creating indirect interactions mediated by the surrounding medium. These interactions significantly influence their collective dynamics, especially in systems with many particles (e.g., active colloids).  \\n2. **Potential Interactions**: Direct forces (e.g., electrostatic, van der Waals) between particles also play a role in their behavior.  \\n3. **Self-Assembly**: Both passive and active colloidal systems can form complex structures via self-organization. Passive systems rely on chemical gradients or external fields (e.g., light, magnetic fields), while active colloids exhibit autonomous motion due to internal energy sources.  \\n4. **Applications**: Colloidal particles are used in advanced technologies, such as optoelectronic devices, biomedical applications (e.g., targeted drug delivery), and dynamic pattern formation.  \\n\\nFor example, the document *Huang et al. (2023)* highlights colloidal self-assembly driven by chemical gradients or external fields, while *Liebchen and Mukhopadhyay (2022)* discusses the challenges of simulating large-scale colloidal systems due to complex interactions. These particles remain a central focus in soft matter physics and materials science.\", 'options': None}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfnavas-f/Projects/DomainMind/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio history: [{'role': 'user', 'metadata': None, 'content': 'What are colloidal particles?', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': \"<details><summary><b>🤔 Thinking</b></summary><pre>Okay, the user is asking about colloidal particles. Let me start by recalling what I know. Colloidal particles are tiny particles suspended in a fluid, right? They're bigger than molecules but smaller than what's visible to the naked eye. Wait, the user provided some documents, so I should check those for specific info.\\n\\nLooking at the documents, there's a mention of colloidal particles in different contexts. For example, one document talks about colloidal systems and hydrodynamic interactions. Another mentions colloidal self-assembly, both passive and active systems. There's also a reference to interactions like phoretic, osmotic, and hydrodynamic. \\n\\nSo, colloidal particles are particles dispersed in a medium, usually liquid, with sizes between 1 nm to 1 micrometer. They can be coated with polymers, as mentioned in one of the texts. The interactions between them include direct potential interactions and indirect hydrodynamic ones. Also, active colloids can move autonomously due to external fields or chemical gradients. \\n\\nI should structure the answer to define colloidal particles, their size range, the medium they're in, and the types of interactions they have. Also, mention their applications like self-assembly and biomedical uses. Need to make sure to reference the documents where applicable, like the hydrodynamic interactions from Dhont's work and the active systems from Huang's paper. Avoid any markdown and keep it clear.</pre></details>\\n\\nColloidal particles are tiny, dispersed entities suspended in a fluid medium (such as liquid or gas), typically ranging in size from **1 nanometer to 1 micrometer**. They are larger than individual molecules or ions but smaller than particles visible to the naked eye. These particles can consist of various materials, such as polymers, inorganic compounds, or biological entities, and are often stabilized by surface coatings or repulsive forces to prevent aggregation.  \\n\\nKey characteristics and contexts from the provided documents:  \\n1. **Hydrodynamic Interactions**: Colloidal particles induce fluid flow around them, creating indirect interactions mediated by the surrounding medium. These interactions significantly influence their collective dynamics, especially in systems with many particles (e.g., active colloids).  \\n2. **Potential Interactions**: Direct forces (e.g., electrostatic, van der Waals) between particles also play a role in their behavior.  \\n3. **Self-Assembly**: Both passive and active colloidal systems can form complex structures via self-organization. Passive systems rely on chemical gradients or external fields (e.g., light, magnetic fields), while active colloids exhibit autonomous motion due to internal energy sources.  \\n4. **Applications**: Colloidal particles are used in advanced technologies, such as optoelectronic devices, biomedical applications (e.g., targeted drug delivery), and dynamic pattern formation.  \\n\\nFor example, the document *Huang et al. (2023)* highlights colloidal self-assembly driven by chemical gradients or external fields, while *Liebchen and Mukhopadhyay (2022)* discusses the challenges of simulating large-scale colloidal systems due to complex interactions. These particles remain a central focus in soft matter physics and materials science.\", 'options': None}, {'role': 'user', 'metadata': None, 'content': 'What is Brownian motion? ', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': \"<details><summary><b>🤔 Thinking</b></summary><pre>Okay, the user is asking about Brownian motion. Let me recall what I know. Brownian motion refers to the random movement of particles suspended in a fluid. It's named after Robert Brown, who observed pollen grains moving in water. The motion is caused by collisions with the fluid molecules. \\n\\nLooking at the context provided, the user mentioned colloidal particles and their behavior. The assistant previously discussed colloidal particles, their size, and interactions. Now, the question is about Brownian motion, which is a key aspect of their dynamics. \\n\\nIn the documents referenced, there's a mention of Brownian dynamics simulations. For example, the Langevin equation is used to model the motion of particles under stochastic forces. The equation includes terms for friction, potential energy, and the Brownian force, which is a random force due to molecular collisions. \\n\\nThe assistant should explain that Brownian motion is the result of these random collisions, leading to the erratic movement observed. It's important to note that this motion is a manifestation of the thermal energy in the fluid, as described by Einstein's theory. The concept ties into the kinetic theory of matter, where particles are in constant motion. \\n\\nAlso, the user might be connecting this to colloidal systems. Since colloidal particles are much larger than molecules, their Brownian motion is more noticeable. The assistant should mention how this motion affects the stability and behavior of colloidal suspensions, such as preventing sedimentation due to the random movement counteracting gravity. \\n\\nIn the context of the documents, there's a mention of simulations using Langevin equations and the role of hydrodynamic interactions. The assistant should clarify that Brownian motion is a part of these simulations, where the stochastic forces are modeled to capture the random thermal fluctuations. \\n\\nI should also consider if there's any mention of the mathematical formulation. For instance, the Langevin equation as presented in the documents includes terms for friction, potential, and the Brownian force, which is Gaussian. The assistant should explain each term's role in the equation. \\n\\nAdditionally, the user might be interested in the historical context or the significance of Brownian motion in understanding molecular motion. The assistant can mention Einstein's 1905 paper and Smoluchowski's work, which provided evidence for the existence of atoms and molecules. \\n\\nIt's important to distinguish Brownian motion from other types of particle movement, like diffusion or sedimentation. The assistant should highlight that Brownian motion is a result of the continuous bombardment by fluid molecules, leading to a net movement that averages out over time but is visible as random paths at the microscopic level. \\n\\nIn summary, the answer should define Brownian motion, explain its cause (collisions with fluid molecules), relate it to thermal energy, mention the mathematical models used in simulations, and connect it to colloidal systems and their behavior.</pre></details>\\n\\nBrownian motion refers to the random, erratic movement of microscopic particles (such as colloidal particles, pollen grains, or molecules) suspended in a fluid (liquid or gas). This phenomenon was first observed by the botanist Robert Brown in 1827, who noticed the continuous, unpredictable motion of pollen grains in water. \\n\\n### Key Characteristics and Causes:\\n1. **Thermal Energy-Driven Motion**:  \\n   Brownian motion arises from the continuous collisions between the suspended particles and the individual molecules of the fluid. These collisions are driven by the thermal energy of the fluid, which causes the fluid molecules to move rapidly and randomly. The larger the fluid molecules, the more pronounced the effect.\\n\\n2. **Stochastic (Random) Nature**:  \\n   The motion is inherently random, as the direction and magnitude of each collision depend on the chaotic, thermal motion of the fluid molecules. Over time, this results in a diffusive, statistical movement of the particles.\\n\\n3. **Scale Dependency**:  \\n   Brownian motion is most observable for particles in the colloidal range (1–1000 nm in size). At this scale, the particles are large enough to be visible under a microscope but small enough that their motion is dominated by thermal fluctuations rather than macroscopic forces like gravity.\\n\\n4. **Mathematical Modeling**:  \\n   The motion is often described by the **Langevin equation**, which incorporates:\\n   - **Frictional forces** (e.g., from fluid viscosity),\\n   - **Potential energy** (e.g., from external fields or interparticle interactions),\\n   - **Random forces** (Brownian force), modeled as Gaussian noise, representing thermal fluctuations.\\n\\n### Connection to Colloidal Systems:\\nIn colloidal suspensions, Brownian motion plays a critical role in:\\n- **Stabilizing suspensions**: The random motion prevents particles from settling due to gravity, maintaining a stable dispersion.\\n- **Self-assembly**: Brownian motion drives the dynamic rearrangement of particles, enabling phenomena like phase separation or the formation of ordered structures in response to external stimuli (e.g., light, electric fields).\\n- **Simulation Techniques**: Brownian dynamics (BD) simulations, as mentioned in the context, model the motion of colloidal particles by integrating Langevin equations, accounting for hydrodynamic interactions, potential forces, and stochastic forces. These simulations are essential for studying complex systems where thermal fluctuations dominate.\\n\\n### Historical and Scientific Significance:\\n- **Einstein’s 1905 paper**: Provided a theoretical framework for Brownian motion, linking it to the kinetic theory of matter and offering experimental evidence for the existence of atoms and molecules.\\n- **Smoluchowski’s work**: Further refined the understanding of Brownian motion and its role in diffusion and particle interactions.\\n\\nIn summary, Brownian motion is a fundamental manifestation of thermal energy at the microscopic scale, driving the dynamic behavior of colloidal systems and enabling phenomena like self-assembly and diffusion. Its study bridges classical mechanics, statistical physics, and modern computational models.\", 'options': None}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfnavas-f/Projects/DomainMind/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def split_think_and_answer(response):\n",
    "    \"\"\"Extracts text after </think>.\"\"\"\n",
    "    match = re.search(r\"</think>\\s*(.*)\", response, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return response.strip()\n",
    "\n",
    "\n",
    "def get_thought(response):\n",
    "    \"\"\"Extracts text inside <think>...</think>.\"\"\"\n",
    "    match = re.search(r\"<think>(.*?)</think>\", response, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "\n",
    "def remove_details_blocks(text):\n",
    "    # Remove all <details>...</details> blocks, including nested tags and multiline content\n",
    "    return re.sub(r\"<details[\\s\\S]*?</details>\", \"\", text, flags=re.DOTALL).strip()\n",
    "\n",
    "\n",
    "def rag_qa_multi_query(message, history):\n",
    "    # Convert Gradio history format to LangChain message format\n",
    "    history_langchain_format = []\n",
    "    print(\"Gradio history:\", history)\n",
    "    # Convert Gradio history (list of {\"role\": ..., \"content\": ...}) to LangChain format\n",
    "    for turn in history:\n",
    "        if turn[\"role\"] == \"user\":\n",
    "            history_langchain_format.append(HumanMessage(content=turn[\"content\"]))\n",
    "        elif turn[\"role\"] == \"assistant\":\n",
    "            cleaned_content = remove_details_blocks(turn[\"content\"])\n",
    "            history_langchain_format.append(AIMessage(content=cleaned_content))\n",
    "\n",
    "    try:\n",
    "        # Pass both current message and history to the chain\n",
    "        response = rag_chain_multi_query.invoke(\n",
    "            {\"history\": history_langchain_format, \"question\": message}\n",
    "        )\n",
    "        thought = get_thought(response)\n",
    "        final_answer = split_think_and_answer(response)\n",
    "\n",
    "        if thought:\n",
    "            # Add collapsible section with the <think> content\n",
    "            final_answer = f\"<details><summary><b>🤔 Thinking</b></summary><pre>{thought}</pre></details>\\n\\n{final_answer}\"\n",
    "        return {\"role\": \"assistant\", \"content\": final_answer}\n",
    "    except Exception as e:\n",
    "        return {\"role\": \"assistant\", \"content\": f\"❌ Error: {str(e)}\"}\n",
    "\n",
    "\n",
    "# Create and launch the chat interface with memory\n",
    "demo = gr.ChatInterface(\n",
    "    fn=rag_qa_multi_query,\n",
    "    type=\"messages\",\n",
    "    title=\"📄 Scientific PDF Chatbot\",\n",
    "    description=\"Ask questions about your scientific PDFs. Powered by RAG + Qwen3:8B\",\n",
    "    examples=[\"What are colloidal particles?\", \"Tell me more about that\"],\n",
    ")\n",
    "\n",
    "demo.launch(share=False, inline=False, inbrowser=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "domainmind",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
